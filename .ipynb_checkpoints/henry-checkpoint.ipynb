{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lined-tanzania",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9a994f11050b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "improved-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desperate-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    " display_labels = ['hospitalized', 'nonhospitalized', 'recovered', 'deceased']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-wallet",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "harmful-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "data['sex'] = labelencoder.fit_transform(data['sex'])\n",
    "data['province'] = labelencoder.fit_transform(data['province'])\n",
    "data['country'] = labelencoder.fit_transform(data['country'])\n",
    "data['date_confirmation'] = labelencoder.fit_transform(data['date_confirmation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-cedar",
   "metadata": {},
   "source": [
    "### Split dataset with ratio 0.8 : 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bearing-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = np.split(data.sample(frac=1),\n",
    "                                        [int(0.8 * len(data))])\n",
    "x_columns = [x for x in training_data.columns if x!='outcome']\n",
    "y_train = training_data['outcome']\n",
    "y_validation = validation_data['outcome']\n",
    "X_train = training_data[x_columns]\n",
    "X_validation = validation_data[x_columns]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['outcome']), data['outcome'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-islam",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjustable-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "disabled-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100, max_depth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "martial-helping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dressed-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = rf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "billion-while",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701220348279172"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_validation, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "irish-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you can save it to a file\n",
    "with open('RandomForest.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)\n",
    "\n",
    "# and later you can load it\n",
    "#with open('filename.pkl', 'rb') as f:\n",
    "    #clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-least",
   "metadata": {},
   "source": [
    "###  Evalution of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equipped-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel = None\n",
    "with open('./RandomForest.pkl', 'rb') as f:\n",
    "    rfModel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bigger-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = rfModel.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "expired-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8865110379816262"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "human-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predict = rf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "chemical-buying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701220348279172"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_validation,valid_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-gasoline",
   "metadata": {},
   "source": [
    "### LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compressed-driving",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-bf5262481c6b>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-bf5262481c6b>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    for label, score in zip(f1_score(y_true, y_pred, average='weighted', label = display_labels))\u001b[0m\n\u001b[1;37m                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "early_stop_rounds = 10\n",
    "def print_all_score(y_true, y_pred):\n",
    "    print('Accuracy score:', accuracy_score(y_true, y_pred))\n",
    "    print('Precision score:', precision_score(y_true, y_pred, average = 'weighted'))\n",
    "    print('Recall score:', recall_score(y_true, y_pred, average = 'weighted'))\n",
    "    print('Kappa score:', cohen_kappa_score(y_true, y_pred))\n",
    "#     for label, score in zip(f1_score(y_true, y_pred, average='weighted', label = display_labels))\n",
    "#         print('Fisher score of ' ,label, \":\" ,score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_lgb = LGBMClassifier(boosting_type = 'gbdt', num_leaves = 200, n_estimators=200).fit(X_train, y_train)\n",
    "dart_lgb = LGBMClassifier(boosting_type = 'dart', num_leaves = 200,n_estimators=200).fit(X_train, y_train)\n",
    "goss_lgb = LGBMClassifier(boosting_type = 'goss', num_leaves = 200,n_estimators=200).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_train_predictions = gbdt_lgb.predict(X_train)\n",
    "gbdt_test_predictions = gbdt_lgb.predict(X_validation)\n",
    "dart_train_predictions = dart_lgb.predict(X_train)\n",
    "dart_test_predictions = dart_lgb.predict(X_validation)\n",
    "goss_train_predictions = goss_lgb.predict(X_train)\n",
    "goss_test_predictions = goss_lgb.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_score(y_train, gbdt_train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_score(y_validation, gbdt_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you can save it to a file\n",
    "# with open('LGBM.pkl', 'wb') as f:\n",
    "#     pickle.dump(lgb, f)\n",
    "\n",
    "# and later you can load it\n",
    "# with open('filename.pkl', 'rb') as f:\n",
    "#     clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_score(y_train, dart_train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_score(y_validation, dart_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_score(y_train, goss_train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_score(y_validation, goss_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-circular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fancy-collapse",
   "metadata": {},
   "source": [
    "## Confusion Matrix for Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(gbdt_lgb, X_train, y_train, display_labels = display_labels, xticks_rotation = 10)\n",
    "disp.ax_.set_title('LGB Confusion Matrix for Training Set')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/lgb_cm_train.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-password",
   "metadata": {},
   "source": [
    "## Confusion Matrix for Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(gbdt_lgb, X_validation, y_validation, display_labels = display_labels, xticks_rotation = 10)\n",
    "disp.ax_.set_title('LGB Confusion Matrix for Training Set')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/lgb_cm_train.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
